# Adversarial Machine Learning

## การเรียนรู้ของเครื่องแบบปฏิปักษ์: การก่อกวน และความทนทาน

เมื่อ machine learning เข้ามามีบทบาทในชีวิตจริงเป็นอย่างมากจนกระทั่งความผิดพลาดจากแบบจำลองอาจนำไปสู่ความเสียหายอย่างใหญ่หลวงหรือกระทั่งนำไปสู่การเสียชีวิต การสร้างแบบจำลองทาง machine learning จะคำนึงถึงแต่ความแม่นยำในการตัดสินใจไม่ได้อีกแล้ว เราจำเป็นต้องสนใจ _ความทนทาน_ (robustness) ของแบบจำลองด้วย ซึ่งหมายถึงความสามารถในการตัดสินใจที่มั่นคงเมื่อข้อมูลที่รับเข้ามามีการปนเปื้อนด้วย noise หรือแม้กระทั่งถูก _ก่อกวน_ (perturb) จากผู้ไม่หวังดี

บทความชุดนี้บันทึกความรู้พื้นฐานทางทฤษฎีที่เกี่ยวข้องกับการก่อกวนแบบจำลองทาง machine learning เช่น deep learning ที่ได้รับความนิยมอย่างมากในปัจจุบัน รวมถึงการเพิ่มความทนทานให้กับ learning model เพื่อป้องกันการถูกก่อกวน
เนื้อหาส่วนใหญ่อ้างอิงจาก [Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org) ของ Zico Kolter และ Aleksander Madry
