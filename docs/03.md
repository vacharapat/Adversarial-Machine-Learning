{% include lib/mathjax.html %}
# การสร้าง adversarial example

จากการนิยาม loss function จะเห็นว่าแบบจำลอง deep learning  $$h_\theta$$ จะมีประสิทธิภาพในการทำนายผลของ input $$x$$ ได้ดีถ้า loss $$\ell(h_\theta(x), y)$$ มีค่าน้อย เมื่อ $$y$$ เป็น label ของคลาสที่ถูกต้องของ $$x$$ ดังนั้น หากเราต้องการก่อกวนแบบจำลองเพื่อให้มีประสิทธิภาพในการทำนายต่ำ เราก็สามารถทำได้โดยการปรับปรุง input $$x$$ เพื่อให้ loss มีค่ามากที่สุด นั่นคือ เราต้องการหา input $$\hat{x}$$ ที่เป็นคำตอบของ

$$
\max_{\hat{x}}\ell(h_\theta(\hat{x}), y)
$$

อย่างไรก็ดี ในความเป็นจริงนั้นใช่ว่าเราจะเลือก $$\hat{x}$$ ใด ๆ มาพิจารณาก็ได้ ตัวอย่างเช่นในปัญหาการจำแนกรูปภาพ หาก $$x$$ เป็นรูปหมูและ $$y$$ เป็น label ของคลาสที่ตอบว่าเป็นหมู หากเราเลือก $$\hat{x}$$ ที่แตกต่างจาก $$x$$ อย่างสิ้นเชิง เช่นเลือก $$\hat{x}$$ เป็นรูปรถ ก็จะไม่สอดคล้องกับความต้องการของเราที่ต้องการ _หลอก_ แบบจำลองให้ตัดสินใจว่ารูปที่รับมาไม่ใช่รูปหมูทั้ง ๆ ที่ในความเป็นจริงรูปนั้นยังคงเป็นรูปหมู ดังนั้นเราจะมองปัญหานี้ใหม่เป็นการใส่ _การก่อกวน_ เล็ก ๆ เข้าไปยัง input $$x$$ เพื่อให้ค่าของ loss สูงที่สุด หากเราแทนการก่อกวนดังกล่าวด้วย $$\delta$$ จะได้ว่าปัญหาที่เราสนใจคือการหา $$\delta$$ ที่เป็นคำตอบของ

$$
\max_{\delta\in\Delta}\ell(h_\theta(x+\delta),y)
$$

โดย $$\Delta$$ เป็นเซตของการก่อกวนที่เป็นไปได้ ในทางอุดมคติเราต้องการให้ $$\Delta$$ เป็นเซตของการก่อกวนที่ยังทำให้มนุษย์เห็นว่าตัวอย่างข้อมูล $$x+\delta$$ นั้นเหมือนกับ $$x$$ ตัวเดิม ในกรณีของรูปภาพ ตัวอย่างการก่อกวนดังกล่าวได้แก่การเพิ่ม noise เล็กน้อยเข้าไปในภาพ การหมุนภาพ การเลื่อนภาพ หรือการเปลี่ยนแปลงส่วนในภาพที่ไม่เกี่ยวข้องกับวัตถุหลัก (เช่นการเปลี่ยนแปลงค่าในพิกเซลที่เป็นท้องฟ้าในรูปหมู) ถึงแม้ว่าเราจะไม่สามารถนิยามเซตของการก่อกวนที่ต้องการทั้งหมดนี้ให้ชัดเจนทางคณิตศาสตร์ได้ การก่อกวนอย่างง่าย ๆ บางรูปแบบก็เพียงพอที่จะทำให้เห็นความเปราะบางของแบบจำลองของเราได้

การก่อกวนที่ถูกนำมาวิเคราะห์เป็นหลักคือการก่อกวนที่อยู่ในรูป

$$
\Delta = \{\delta:\|\delta\|\leq \epsilon\}
$$

เมื่อ $$\|\delta\|$$ แทน norm หรือขนาดของ $$\delta$$ ซึ่ง norm รูปแบบหนึ่งที่น่าสนใจคือ $$\ell_\infty$$-norm ซึ่งมีนิยามดังนี้

$$
\|d\|_\infty = \max_i |d_i|
$$

กล่าวได้อีกอย่างคือ เมื่อเราพิจารณาการก่อกวนในเซต $$\Delta = \{\delta:\|\delta\|_\infty\leq\epsilon\}$$ หมายความว่าเรายอมให้ค่าในแต่ละมิติของ input $$x$$ เพิ่มขึ้นหรือลดลงจากเดิมได้ไม่เกิน $$\epsilon$$ นั่นเอง หากเรากำหนดค่า $$\epsilon$$ น้อย ๆ จนรับประกันว่าภาพที่ถูกก่อกวนแล้วยังคงเห็นได้ไม่ต่างจากเดิมแน่นอน เราก็สามารถใช้การก่อกวนลักษณะนี้ทดลองโจมตีแบบจำลองเพื่อทดสอบความทนทานได้

ใน [Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org) มีตัวอย่างการทดสอบการก่อกวนแบบจำลอง deep learning โดยใช้แบบจำลอง ResNet50 ที่ถูกเทรนมาสำหรับจำแนกรูปภาพออกเป็น 1000 คลาส เมื่อเราสั่งให้ทำนายรูปหมูด้านล่างนี้ แบบจำลองสามารถทำนายว่าเป็นรูปหมูได้ด้วยความน่าจะเป็น 0.996 

<p align="center">
<img width="350" src="">
</p>
