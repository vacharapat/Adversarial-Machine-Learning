{% include lib/mathjax.html %}
# การสร้าง robustness certificate

หลังจากที่เราได้รู้จักการสร้าง adversarial example เพื่อใช้ในการโจมตีแบบจำลองทาง machine learning และการทำ adversarial training เพื่อเพิ่มความทนทานให้แก่แบบจำลองแล้ว ในหัวข้อนี้เราจะมาสนใจเกี่ยวกับการทดสอบความทนทานของแบบจำลองเมื่อเราพิจารณาที่จุด sample $$x$$ ใด ๆ กล่าวคือ เราอยากทราบว่าหาก sample $$x$$ ของเราถูกก่อกวนด้วยการก่อกวน $$\delta$$ ใด ๆ ในขอบเขต $$\|\delta\|_\infty\leq\epsilon$$ จะมีโอกาสที่แบบจำลองของเราเปลี่ยนผลการทำนายไปจากเดิมหรือไม่ หากเราสามารถรับประกันได้ว่าภายในขอบเขตการก่อกวนดังกล่าว ไม่มีการก่อกวนใด ๆ สามารถทำให้แบบจำลองของเราทำนายผิดไปจากเดิมได้เลย แสดงว่าแบบจำลองของเราได้รับการยืนยันแล้วว่ามีความทนทานต่อการก่อกวนภายในระยะห่าง $$\epsilon$$ ที่จุด $$x$$ แน่นอน เราอาจเรียกการยืนยันดังกล่าวว่าเป็น robustness certificate 

## constrained fomulation ของการโจมตีแบบกำหนดเป้าหมาย

เพื่อสร้าง robustness certificate เราจะเริ่มจากการกลับมามองปัญหา maximization สำหรับการสร้าง adversarial example ใหม่ พิจารณาการเขียนการคำนวณของแบบจำลอง deep ReLU network $$d$$ layer ของเราดังนี้

$$
\begin{split}
z_1&=&x\\
z_{i+1}&=&f_i(W_iz_i+b_i), \text{ for } i=1,\dots,d\\
h_\theta(x)&=&z_{d+1}
\end{split}
$$

