{% include lib/mathjax.html %}
# แบบจำลอง deep learning พอสังเขป

พิจารณาปัญหาการจำแนกข้อมูล ถ้าให้ $$\mathcal{X}$$ เป็น input space เราสามารถมองแบบจำลอง deep learning เป็นฟังก์ชัน

$$
h_\theta : \mathcal{X}\rightarrow \mathbb{R}^k
$$

ที่รับข้อมูลจาก $$\mathcal{X}$$ และให้ผลเป็นเวกเตอร์ของจำนวนจริง $$k$$ มิติ เมื่อ $$k$$ เป็นจำนวนของชนิดข้อมูลที่ต้องการจำแนก ตัวอย่างเช่น หากเราต้องการจำแนกภาพสีขนาด 244$$\times$$244 พิกเซล ออกเป็น 1000 ชนิด เราสามารถสร้างแบบจำลองให้รับ input $$x$$ ใด ๆ เป็นเวกเตอร์ขนาด 244$$\times$$244$$\times$$3 มิติ โดยที่สมาชิกแสดงความเข้มของแสงสีแดง / เขียว / น้ำเงิน ในแต่ละพิกเซล และให้ผลลัพธ์เป็นเวกเตอร์ 1000 มิติ ($$k=1000$$) สัญลักษณ์ $$\theta$$ ใน $$h_\theta$$ เป็นเวกเตอร์ที่แสดงพารามิเตอร์ทั้งหมดของแบบจำลอง เช่นค่า weight matrix ใน fully-connected layer หรือค่า weight ใน convolutional filter เป็นต้น ซึ่งค่าของเวกเตอร์ $$\theta$$ นี้จะถูกปรับให้เหมาะสมที่สุดเท่าที่จะทำได้ในขั้นตอนของการเทรนข้อมูลนั่นเอง

## Loss function
ในการพิจารณาความเหมาะสมของ $$\theta$$ เราต้องเริ่มจากการนิยาม loss function

$$
\ell: \mathbb{R}^k\times \mathbb{Z}_+\rightarrow \mathbb{R}_+
$$

ให้เป็นฟังก์ชันที่รับผลลัพธ์จาก $$h_\theta$$ กับ label ที่ถูกต้อง และคืนค่าเป็นจำนวนจริงที่ไม่น้อยกว่าศูนย์ ซึ่งเราจะเรียกว่า loss หรือมูลค่าความเสียหายเมื่อเทียบผลการทำนายกับคลาสที่ถูกต้อง กล่าวอีกอย่างคือ

$$
\ell(h_\theta(x), y)
$$

เป็น loss หรือความเสียหายเมื่อคลาสที่ถูกต้องคือ $$y$$ และผลการทำนายเป็น $$h_\theta(x)$$

โดยทั่วไปแล้ว สำหรับการจำแนกข้อมูลหลายคลาสเรามักจะแปลงผลของ $$h_\theta(x)$$ ให้อยู่ในรูปการกระจายความน่าจะเป็นโดยใช้ฟังก์ชัน _softmax_ $$\sigma: \mathbb{R}^k\rightarrow\mathbb{R}^k$$ ซึ่งมีนิยามดังนี้

$$
\sigma(z)_i=\frac{e^{z_i}}{\sum_{i=1}^ke^{z_j}}
$$

สำหรับตัวอย่างข้อมูล $$(x, y)$$ เมื่อ $$x$$ เป็น input และ $$y$$ เป็นคลาสที่ถูกต้องของ $$x$$
หลังจากที่เราทำการคำนวณกระจายความน่าจะเป็น $$\sigma(h_\theta(x))$$ แล้ว เราต้องการให้ความน่าจะเป็นของคลาสที่ถูกต้องซึ่งคือค่าของ $$\sigma(h_\theta(x))_y$$ มีค่ามากที่สุดเพื่อที่จะได้ทำนายคลาสผลลัพธ์ได้ถูกต้อง
โดยปกติความน่าจะเป็นนี้จะมีค่าน้อยมาก เราจึงมักจะพิจารณาค่า logarithm ของความน่าจะเป็นนี้แทน นั่นคือ เราต้องการให้

$$
\begin{split}
\log\sigma(h_\theta(x))_y &= \log\left(\frac{e^{h_\theta(x)_y}}{\sum_{j=1}^ke^{h_\theta(x)_j}}\right)\\
&= h_\theta(x)_y - \log\sum_{j=1}^ke^{h_\theta(x)_j}
\end{split}
$$

มีค่ามากที่สุด
จากตรงนี้ จะเห็นว่าหากเรานิยามให้ loss ที่เกิดจากตัวอย่างข้อมูล $$(x, y)$$ เป็น

$$
\ell(h_\theta(x), y) = - \log\sigma(h_\theta(x))_y  = \log\sum_{j=1}^ke^{h_\theta(x)_j} - h_\theta(x)_y
$$

เราก็จะได้ว่าแบบจำลองนี้สอดคล้องกับตัวอย่างข้อมูล $$(x, y)$$ เมื่อ loss $$\ell(h_\theta(x), y)$$ มีค่าน้อย ฟังก์ชัน loss นี้มีชื่อเรียกว่า _softmax cross entropy_

## การเทรนแบบจำลอง

ในกระบวนการเทรนแบบจำลอง deep learning นั้น เราจะได้รับเซตของตัวอย่างข้อมูล $$S=\{(x_1, y_1),\dots,(x_m,y_m)\}$$ โดยที่ $$x_i\in \mathcal{X}$$ และ $$y_i\in\{1,\dots,k\}$$ สำหรับ $$i=1,\dots, m$$ เราเรียก $$S$$ นี้ว่า training set ซึ่งจะใช้ในการคำนวณค่าของพารามิเตอร์ $$\theta$$ ที่เหมาะสม โดยเราต้องการหาค่าของ $$\theta$$ ที่ทำให้ค่าเฉลี่ย loss ของตัวอย่างข้อมูลใน $$S$$ มีค่าน้อยที่สุด เราสามารถเขียนปัญหานี้ในรูปแบบของปัญหา optimization ได้ดังนี้

$$
\min_\theta \frac{1}{m}\sum_{i=1}^m\ell(h_\theta(x_i),y_i)
$$

อัลกอริทึมพื้นฐานในการแก้ปัญหานี้เรียกว่า _stochastic gradient descent_ ซึ่งจะวนรอบปรับค่า $$\theta$$ ให้ค่าเฉลี่ยของ loss นี้ลดลงเรื่อย ๆ โดยในแต่ละรอบ เราพิจารณา _minibatch_ $$\mathcal{B}\subseteq S$$ และทำการคำนวณ _เกรเดียนต์_ (gradient) ของค่าเฉลี่ย loss ของ $$\mathcal{B}$$ เมื่อเทียบกับ $$\theta$$ ซึ่งเขียนแทนด้วย

$$
\nabla_\theta\left(\frac{1}{|\mathcal{B}|}\sum_{(x,y)\in\mathcal{B}}\ell(h_\theta(x),y)\right)
= \frac{1}{|\mathcal{B}|}\sum_{(x,y)\in\mathcal{B}}\nabla_\theta\ell(h_\theta(x),y)
$$

โดยการคำนวณเกรเดียนต์สามารถทำได้โดยเทคนิคที่เรียกว่า backpropogation จากนั้นเราทำการปรับ $$\theta$$ ไปยังทิศทางตรงข้ามกับเกรเดียนต์โดย หาก $$\theta_t$$ เป็นค่าของพารามิเตอร์ $$\theta$$ หลังการทำงานรอบที่ $$t$$ เราจะปรับให้

$$
\theta_{t+1}=\theta_t-\alpha\cdot\frac{1}{|\mathcal{B}|}\sum_{(x,y)\in\mathcal{B}}\nabla_\theta\ell(h_\theta(x),y)
$$

เมื่อ $$\alpha>0$$ เป็นค่าคงที่เรียกว่า _learning rate_

เราจะทำการวนรอบปรับ $$\theta$$ เช่นนี้เรื่อย ๆ จนกระทั่ง $$\theta$$ ลู่เข้าสู่ค่าคงที่ หรือมีการเปลี่ยนแปลงน้อยว่าค่าที่กำหนดก็เป็นอันเสร็จสิ้นกระบวนการเทรน

## การทดสอบ

หากแบบจำลอง deep learning ที่เราใช้มีความซับซ้อนมาก จะทำให้แบบจำลองมีความสามารถในการปรับค่าพารามิเตอร์ให้เข้ากับข้อมูลที่ใช้สอนได้ดี ซึ่งอาจเกิดปัญหาได้หากแบบจำลองของเราปรับตัวให้เข้ากับข้อมูลใน training set มากเกินไป แต่ไม่มีความ generalize นั่นคือ เมื่อนำแบบจำลองไปทดสอบบนชุดข้อมูลที่ไม่เคยเห็นมาก่อนกลับพบว่ามีความแม่นยำน้อย เราเรียกปัญหานี้ว่า _overfit_ ในกระบวนการเทรนแบบจำลองทาง machine learning โดยทั่วไป มักจะนำชุดข้อมูลที่มีแบ่งออกเป็นสามส่วน
ได้แก่

- ชุดข้อมูลที่ใช้สอนแบบจำลอง เรียกว่า training set มักจะมีขนาดใหญ่เนื่องจากต้องการความหลากหลายให้แบบจำลองได้นำไปเรียนรู้ที่จะสกัดคุณสมบัติที่เหมาะสมในการตัดสินใจ
- ชุดข้อมูลที่ใช้ในการทดสอบขั้นต้น เรียกว่า validation set ใช้สำหรับทดสอบความ generalize ของแบบจำลองว่ามีความสามารถในการตัดสินใจบนข้อมูลที่ไม่เคยเห็นในตอนเทรนได้ดีแค่ไหน เรามักใช้ validation set ในการทดสอบความ overfit ของแบบจำลองระหว่างการเทรน โดยหากเราพบว่าความแม่นยำบน validation set เริ่มลดลงในขณะที่ความแม่นยำบน training set ยังคงเพิ่มขึ้น แสดงว่าแบบจำลองของเราเริ่ม overfit แล้ว นอกจากนี้ หากเรามีแบบจำลองที่ผ่านการเทรนด้วย training set มาแล้วหลายแบบจำลอง เราสามารถใช้ validation set ช่วยในการเลือกได้ โดยแบบจำลองที่น่าสนใจก็คือแบบจำลองที่มีความแม่นยำบน validation set สูง
- ชุดข้อมูลทดสอบ เรียกว่า test set เป็นชุดข้อมูลที่แบบจำลองไม่เคยเห็นอีกเช่นกัน ใช้สำหรับทดสอบความแม่นยำของแบบจำลองสุดท้ายหลังจากที่ทำการเลือกแบบจำลองแล้ว

อย่างไรก็ดี ตัวอย่างต่าง ๆ ในบทความชุดนี้เราจะไม่มีการใช้ validation set ในการทดสอบความ overfit เพื่อความสะดวกในการสร้างแบบจำลอง

## References
1. [Z. Kolter, A. Madry. Adversarial Robustness - Theory and Practice](https://adversarial-ml-tutorial.org)
1. [I. Goodfellow, Y. Bengio, A.Courville. Deep Learning, MIT Press, 2016](http://www.deeplearningbook.org)

---
Next: [การสร้าง adversarial example](https://vacharapat.github.io/Adversarial-Machine-Learning/docs/intro2)
