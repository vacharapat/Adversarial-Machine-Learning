{% include lib/mathjax.html %}
# Adversarial robustness

เราได้เห็นตัวอย่างการโจมตีแบบจำลอง deep learning กันมาแล้ว คราวนี้เราจะมาพิจารณาในฝั่งของผู้สร้างแบบจำลองกันดูบ้างว่าเราจะสามารถสร้างแบบจำลองที่มี _ความทนทานต่อการโจมตี_ (adversarial robustness) เหล่านี้ได้อย่างไร โดยลำดับแรกเราจะมาทบทวนหัวใจหลักของการเทรนแบบจำลอง deep learning ในรูปแบบปกติกันก่อน

## Risk ของแบบจำลอง

สำหรับแบบจำลองทาง machine learning $$h_\theta$$ ใด ๆ เรานิยามให้ _risk_ ของแบบจำลองนี้เป็นค่าเฉลี่ยหรือ _ค่าคาดหวัง_ (expectation) ของ loss ดังนี้ 

$$
R(h_\theta) = \mathbb{E}_{(x,y)\sim \mathcal{D}}[\ell(h_\theta(x), y)]
$$

เมื่อ $$\mathcal{D}$$ เป็นการกระจายตัวของข้อมูลทั้งหมด ซึ่งในทางปฏิบัติเราไม่ทราบ $$\mathcal{D}$$ ที่แท้จริง เราจึงต้องทำการประมาณการกระจายตัวดังกล่าวจากเซตของตัวอย่างข้อมูล $$D=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ ซึ่ง $$(x_i, y_i)$$ แต่ละตัวนั้นสุ่มมาจาก $$\mathcal{D}$$ 
