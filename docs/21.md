{% include lib/mathjax.html %}
# Sample complexity
จากหัวข้อที่แล้ว เราได้ทำการวิเคราะห์ generalization bound ของ risk ของ hypothesis ที่ได้จากการเรียนรู้โดยขึ้นอยู่กับจำนวนตัวอย่างข้อมูลที่ใช้เทรนและ VC dimension กันมาแล้ว ในหัวข้อนี้เราจะมาวิเคราะห์ในมุมของ sample complexity กันดูบ้างว่าหากเราต้องการได้ hypothesis ที่มี risk แตกต่างจาก hypothesis ที่ดีที่สุดไม่เกิน $\epsilon$ ด้วยความน่าจะเป็นสูง เราจะต้องการตัวอย่างข้อมูลใน training set มากแค่ไหน

## consistent hypothesis
ในกรณีที่เราสามารถหา hypothesis ที่ consistent กับตัวอย่างข้อมูล $$S=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ ได้เสมอ
จากการวิเคราะห์ generalization bound ในหัวข้อก่อน เราจะได้ว่า 

$$
\Pr[\exists h\in H: R(h)>\epsilon \text{ และ } h \text{ consistent กับ } S]\leq 2\left(\frac{2em}{d}\right)^d2^{-\epsilon m/2}
$$

ดังนั้นหากเราต้องการให้เหตุการณ์ดังกล่าวเกิดขึ้นด้วยความน่าจะเป็นไม่เกิน $\delta$ เราสามารถกำหนดให้

$$
2\left(\frac{2em}{d}\right)^d2^{-\epsilon m/2}\leq\delta
$$

ก็จะได้ว่า จำนวนตัวอย่างข้อมูลที่ต้องใช้จะต้องมีค่าเป็น

$$
m\geq \frac{1}{\epsilon}\left(d\log_2\frac{2em}{d}+\log_2\frac{2}{\delta}\right)
$$
