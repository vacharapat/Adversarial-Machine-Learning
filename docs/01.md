{% include lib/mathjax.html %}
# แบบจำลอง deep learning พอสังเขป

พิจารณาปัญหาการจำแนกข้อมูล ถ้าให้ $$\mathcal{X}$$ เป็น input space เราสามารถมองแบบจำลอง deep learning เป็นฟังก์ชัน $$h_\theta : \mathcal{X}\rightarrow \mathbb{R}^k$$ ที่รับข้อมูลจาก $$\mathcal{X}$$ และให้ผลเป็นเวกเตอร์ของจำนวนจริง $$k$$ มิติ เมื่อ $$k$$ เป็นจำนวนของชนิดข้อมูลที่ต้องการจำแนก ตัวอย่างเช่น หากเราต้องการจำแนกภาพสีขนาด 244$$\times$$244 พิกเซล ออกเป็น 1000 ชนิด เราสามารถสร้างแบบจำลองให้รับ input $$x$$ ใด ๆ เป็นเวกเตอร์ขนาด 244$$\times$$244$$\times$$3 มิติ โดยที่สมาชิกแสดงความเข้มของแสงสีแดง / เขียว / น้ำเงิน ในแต่ละพิกเซล และให้ผลลัพธ์เป็นเวกเตอร์ 1000 มิติ ($$k=1000$$) สัญลักษณ์ $$\theta$$ ใน $$h_\theta$$ เป็นเวกเตอร์ที่แสดงพารามิเตอร์ทั้งหมดของแบบจำลอง เช่นค่า weight matrix ใน fully-connected layer หรือค่า weight ใน convolutional filter เป็นต้น ซึ่งค่าของเวกเตอร์ $$\theta$$ นี้จะถูกปรับให้เหมาะสมที่สุดเท่าที่จะทำได้ในขั้นตอนของการเทรนข้อมูลนั่นเอง

ในการพิจารณาความเหมาะสมของ $$\theta$$ เรานิยาม loss function $$\ell: \mathbb{R}^k\times \mathbb{Z}_+\rightarrow \mathbb{R}_+$$ เป็นฟังก์ชันที่รับผลลัพธ์จาก $$h_\theta$$ กับ label ที่ถูกต้อง และคืนค่าเป็นจำนวนจริงที่ไม่น้อยกว่าศูนย์ ซึ่งเราใช้แทน loss หรือมูลค่าความเสียหายเมื่อเทียบผลการทำนายกับคลาสที่ถูกต้อง กล่าวอีกอย่างคือ $$\ell(h_\theta(x), y)$$ เป็น loss หรือความเสียหายเมื่อคลาสที่ถูกต้องคือ $$y$$ และผลการทำนายเป็น $$h_\theta(x)$$


