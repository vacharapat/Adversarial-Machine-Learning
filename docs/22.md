{% include lib/mathjax.html %}
# Lower bound

ในหัวข้อก่อนหน้า เราได้เห็นขอบเขตบนของ generalization error หรือ sample complexity ของการเรียนรู้แบบ PAC กันมาแล้ว
ในหัวข้อนี้เราจะมาวิเคราะห์ _ขอบเขตล่าง_ (lower bound) กันดูบ้าง เนื่องจากกรอบการเรียนรู้แบบ PAC นี้ไม่ขึ้นกับการกระจายของข้อมูล กล่าวคือ 
เราสามารถประยุกต์ใช้ผลจากการศึกษาของ PAC ได้โดยไม่จำเป็นต้องทราบว่าการกระจายของข้อมูลที่เราสนใจมีลักษณะเป็นอย่างไร
ขอเพียงเป็นการกระจายที่คงที่แบบใดแบบหนึ่ง ดังนั้นในการหาขอบเขตล่างเราอาจทำได้โดยแสดงให้เห็นการกระจายของข้อมูลที่ generalization error ไม่มีทางต่ำกว่าค่าหนึ่งด้วยความน่าจะเป็นที่มากกว่าศูนย์ หรือในมุมของ sample complexity ก็คือ เราจะแสดงให้เห็นว่ามีการกระจายของข้อมูลที่ เมื่อจำนวนตัวอย่างข้อมูลน้อยกว่าค่าหนึ่ง เรามีโอกาสที่ hypothesis ผลลัพธ์จากการเรียนรู้จะมี risk มากกว่า $\epsilon$ ด้วยความน่าจะเป็นที่มากกว่าศูนย์

## $\Omega(d)$- sample complexity bound
ในขั้นแรกนี้เราจะแสดงตัวอย่างการวิเคราะห์ขอบเขตล่าง โดยจะแสดงให้เห็นว่าจำนวนตัวอย่างข้อมูลที่ต้องการเพื่อเรียนรู้ให้สำเร็จนั้นมีขอบเขตล่างเป็น $\Omega(d)$ เมื่อ $d$ เป็น VC dimenstion ของ hypothesis space ที่เราสนใจ

พิจารณา hypothesis space $H$ ที่มี VC dimension เท่ากับ $d$ ให้ $$X=\{x_1,\dots,x_d\}$$ เป็นเซตของตัวอย่างข้อมูลที่ถูก shatter ได้ด้วย $H$ 
และกำหนดให้ตัวอย่างข้อมูล $x_i$ แต่ละตัวมีความน่าจะเป็นที่จะถูกสุ่มได้เท่ากับ $1/d$ เท่ากันทั้งหมด สังเกตว่าเราสามารถมอง $H$ ให้มีขนาดจำกัดโดยมีจำนวน hypothesis เท่ากับ $2^d$ โดยที่ สำหรับการ label ตัวอย่างข้อมูลใน $X$ แต่ละแบบ จะมี hypothesis ใน $H$ เพียงแบบเดียวเท่านั้นที่สอดคล้องกับการ label ดังกล่าว สังเกตว่าการสุ่มเลือก concept เป้าหมาย $c\in H$ นั้นสามารถทำได้โดยการสุ่มเลือก label ให้กับข้อมูล $x_i\in X$ แต่ละตัว

คราวนี้สมมติให้ concept เป้าหมาย $c$ นั้นถูกสุ่มมาจาก $H$ จากนั้น เมื่อเราสุ่มหยิบตัวอย่างข้อมูลใน $X$ มา $m$ ตัวได้เป็นเซต $$S=\{x_1,\dots,x_{m}\}$$ 
เราจะได้ว่าผลของการดำเนินการนี้จะมีการกระจายเหมือนกับเราสุ่มหยิบตัวอย่างข้อมูล $S$ จาก $X$ มาก่อนจำนวน $m$ ตัวโดยข้อมูลทุกตัวยังไม่ถูก label จากนั้นเราค่อยสุ่ม label $c(x_i)$ ให้กับตัวอย่างข้อมูลแต่ละตัวทั้งที่อยู่ใน $S$ และไม่อยู่ใน $S$ แล้วให้ $c$ เป็น concept ใน $H$ ที่สอดคล้องกับการ label ที่ได้นี้

จากตรงนี้ถ้าเราให้ $h_S\in H$ เป็น hypothesis ที่ consistent กับ $S$ และให้ $R_c(h_S)$ แทน risk ของ $h_S$ เมื่อเทียบกับ concept $c$ จะได้ว่า

$$
\begin{split}
\mathbb{E}_c[\mathbb{E}_S[R_c(h_S)]]&=\mathbb{E}_c[\mathbb{E}_S[\Pr_{x\in X}[h_S(x)\neq c(x)]]]\\
&\geq\mathbb{E}_c[\mathbb{E}_S[\Pr_{x\in X}[x\notin S, h_S(x)\neq c(x)]]]\\
&=\mathbb{E}_c[\mathbb{E}_S[\Pr_{x\in X}[x\notin S]\cdot \Pr[h_S(x)\neq c(x)|x\notin S]]]
\end{split}
$$


ถ้าเรากำหนดให้ $m\leq d/2$ เราจะได้ว่า  $\Pr_{x\in X}[n\notin S]\geq 1/2$ และเนื่องจาก 
$\Pr[h_S(x)\neq c(x)|x\notin S]= 1/2$
เราจึงได้ว่า

$$
\begin{split}
\mathbb{E}_c[\mathbb{E}_S[R_c(h_S)]]&\geq \mathbb{E}_c[\mathbb{E}_S[\frac{1}{2}\cdot\frac{1}{2}]]\\
&=\frac{1}{4}
\end{split}
$$

สังเกตว่าการที่ expectation ของ $$\mathbb{E}_S[R_c(h_S)]$$ บนการสุ่ม concept $c\in H$ จะมีค่าไม่ต่ำกว่า $1/4$ ได้นั้น แสดงว่าจะต้องมี concept $$c^*\in H$$ อย่างน้อยตัวหนึ่งที่ $$\mathbb{E}_S[R_{c^*}(h_S)]\geq 1/4$$ แน่นอน

คราวนี้หากเราพิจารณา concept $c^*$ ดังกล่าว เนื่องจาก

$$
\begin{split}
\mathbb{E}_S[R_{c^*}(h_S)]&=\sum_{r=0}^1 r\Pr_S[R_{c^*}(h_S)=r]\\
&\leq \sum_{r\leq 1/8}\frac{1}{8}\Pr[R_{c^*}(h_S)=r] + \sum_{1/8<r\leq 1}1\cdot\Pr[R_{c^*}(h_S)=r]\\
&=\frac{1}{8}\Pr[R_{c^*}(h_S)\leq \frac{1}{8}] + \Pr[R_{c^*}(h_S)> \frac{1}{8}]\\
&\leq \frac{1}{8} + \Pr[R_{c^*}(h_S)> \frac{1}{8}]
\end{split}
$$

ดังนั้นเราจึงได้ว่า

$$
\begin{split}
\Pr[R_{c^*}(h_S)> \frac{1}{8}] +\frac{1}{8}\geq \mathbb{E}_S[R_{c^*}(h_S)]\geq \frac{1}{4}
\end{split}
$$

ดังนั้น

$$
\Pr[R_{c^*}(h_S)> \frac{1}{8}]\geq\frac{1}{8}
$$

จากตรงนี้จะเห็นว่า หากเราต้องการทำการเรียนรู้แบบ PAC โดยกำหนดให้ $\epsilon\leq 1/8$ และ $\delta< 1/8$ ลักษณะข้อมูลและ hypothesis space แบบนี้จะทำให้เราไม่สามารถเรียนรู้ตามต้องการได้โดยใช้ตัวอย่างข้อมูล $d/2$ ตัว ดังนั้นเราจึงได้ว่าหากเราพิจารณาเมื่อไม่ทราบการกระจายของข้อมูลที่แท้จริง การเรียนรู้แบบ PAC เมื่อ hypothesis space มี VC dimension เป็น $d$ นั้น จะต้องมี sample complexity ไม่ต่ำกว่า $d/2$ หรือกล่าวได้ว่าขอบเขตล่างของ sample complexity เป็น $\Omega(d)$ นั่นเอง

## ขอบเขตที่ดีขึ้น

จากที่เราเห็นว่ามีตัวอย่างปัญหาการเรียนรู้บางแบบที่ต้องการจำนวนตัวอย่างข้อมูลเป็น $\Omega(d)$ ในความเป็นจริง เราสามารถแสดงให้เห็นการกระจายของข้อมูลอีกแบบหนึ่งซึ่งมีลักษณะคล้าย ๆ เดิม กล่าวคือ เรากำหนดให้ $$X=\{x_0,x_1,\dots,x_{d-1}\}$$ เป็นเซตของตัวอย่างข้อมูลที่ถูก shatter ได้โดย $H$ โดยที่ $d$ เป็น VC dimension ของ $H$ หากเรากำหนดความน่าจะเป็นที่จะสุ่มหยิบ $x_i$ แต่ละตัวได้ดังนี้ สมมติให้ $\epsilon>0$ เราจะกำหนดให้ความน่าจะเป็นที่จะสุ่มหยิบได้ $x_0$ มีค่าสูงเท่ากับ $1-8\epsilon$ และข้อมูลที่เหลือมีโอกาสสุ่มโดนเท่ากัน ซึ่งเท่ากับ $\frac{8\epsilon}{d-1}$ ด้วยลักษณะข้อมูลเช่นนี้ เราจะสามารถวิเคราะห์ด้วยเทคนิคคล้าย ๆ เดิมได้ว่า จำนวนตัวอย่างข้อมูลที่จำเป็นในการเรียนรู้จะต้องมีค่าเป็น $\Omega(d/\epsilon)$ หรือสามารถมองในอีกมุมได้ว่ามีการกระจายของข้อมูลที่ hypothesis ที่ได้จากการเรียนรู้จะมี generalization error เป็น $\Omega(d/m)$ เมื่อ $m$ เป็นจำนวนตัวอย่างข้อมูลที่ใช้ในการเรียนรู้นั่นเอง

## inconsistent hypothesis

ในกรณีที่การเรียนรู้ของเราให้ผลเป็น hypothesis ที่ไม่ consistent กับตัวอย่างข้อมูล $S$ ทั้งหมด เราสามารถแสดงให้เห็นว่าสำหรับอัลกอริทึมการเรียนรู้ใด ๆ จะมีการกระจายของข้อมูลที่มีโอกาสมากกว่าค่าคงที่ค่าหนึ่งที่ hypothesis ผลลัพธ์ที่ได้มี risk สูงกว่า hypothesis ที่ดีที่สุดเป็น $\Omega(\sqrt{\frac{d}{m}})$ หรือสามารถสรุปได้ว่ามีปัญหาการเรียนรู้ที่ต้องการ sample complexity เป็น $\Omega(\frac{d}{\epsilon^2})$
