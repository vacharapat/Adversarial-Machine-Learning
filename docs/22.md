{% include lib/mathjax.html %}
# Lower bound

ในหัวข้อก่อนหน้า เราได้เห็นขอบเขตบนของ generalization error หรือ sample complexity ของการเรียนรู้แบบ PAC กันมาแล้ว
ในหัวข้อนี้เราจะมาวิเคราะห์ _ขอบเขตล่าง_ (lower bound) กันดูบ้าง เนื่องจากกรอบการเรียนรู้แบบ PAC นี้ไม่ขึ้นกับการกระจายของข้อมูล กล่าวคือ 
เราสามารถประยุกต์ใช้ผลจากการศึกษาของ PAC ได้โดยไม่จำเป็นต้องทราบว่าการกระจายของข้อมูลที่เราสนใจมีลักษณะเป็นอย่างไร
ขอเพียงเป็นการกระจายที่คงที่แบบใดแบบหนึ่ง ดังนั้นในการหาขอบเขตล่างเราอาจทำได้โดยแสดงให้เห็นการกระจายของข้อมูลที่ generalization error ไม่มีทางต่ำกว่าค่าหนึ่งด้วยความน่าจะเป็นที่มากกว่าศูนย์ หรือในมุมของ sample complexity ก็คือ เราจะแสดงให้เห็นว่ามีการกระจายของข้อมูลที่ เมื่อจำนวนตัวอย่างข้อมูลน้อยกว่าค่าหนึ่ง เรามีโอกาสที่ hypothesis ผลลัพธ์จากการเรียนรู้จะมี risk มากกว่า $\epsilon$ ด้วยความน่าจะเป็นที่มากกว่าศูนย์

## $\Omega(d)$- sample complexity bound
ในขั้นแรกนี้เราจะแสดงตัวอย่างการวิเคราะห์ขอบเขตล่าง โดยจะแสดงให้เห็นว่าจำนวนตัวอย่างข้อมูลที่ต้องการเพื่อเรียนรู้ให้สำเร็จนั้นมีขอบเขตล่างเป็น $\Omega(d)$ เมื่อ $d$ เป็น VC dimenstion ของ hypothesis space ที่เราสนใจ

พิจารณา hypothesis space $H$ ที่มี VC dimension เท่ากับ $d$ ให้ $$X=\{x_1,\dots,x_d\}$$ เป็นเซตของตัวอย่างข้อมูลที่ถูก shatter ได้ด้วย $H$ 
และกำหนดให้ตัวอย่างข้อมูล $x_i$ แต่ละตัวมีความน่าจะเป็นที่จะถูกสุ่มได้เท่ากับ $1/d$ เท่ากันทั้งหมด สังเกตว่าเราสามารถมอง $H$ ให้มีขนาดจำกัดโดยมีจำนวน hypothesis เท่ากับ $2^d$ โดยที่ สำหรับการ label ตัวอย่างข้อมูลใน $X$ แต่ละแบบ จะมี hypothesis ใน $H$ เพียงแบบเดียวเท่านั้นที่สอดคล้องกับการ label ดังกล่าว สังเกตว่าการสุ่มเลือก concept เป้าหมาย $c\in H$ นั้นสามารถทำได้โดยการสุ่มเลือก label ให้กับข้อมูล $x_i$ แต่ละตัว

คราวนี้สมมติให้ concept เป้าหมาย $c$ นั้นถูกสุ่มมาจาก $H$ เมื่อเราสุ่มหยิบตัวอย่างข้อมูลใน $X$ มา $m$ ตัว ให้ $m'$ เป็นจำนวนตัวอย่างข้อมูลที่แตกต่างกันทั้งหมดที่เราได้มา สมมติให้ $$S=\{x_1,\dots,x_{m'}\}$$ เป็นเซตของตัวอย่างข้อมูลดังกล่าว จะเห็นว่าปัญหาของการทำนาย $c$ ที่ถูกต้องนั้นก็คือการทำนาย label ของสมาชิก $x_j\in X-S$ ที่ไม่เห็นใน $S$ ให้ถูกต้องทั้งหมดนั่นเอง ดังนั้นถ้าให้ $h\in H$ เป็น hypothesis ผลลัพธ์ของการทำนาย และให้ $R_c(h)$ เป็น risk ของ hypothesis $h$ เมื่อเทียบกับ concept เป้าหมาย $c$ เราจะได้ว่า

$$
\begin{split}
\mathbb{E}_{c\in H}[R_c(h)]&=\sum_{c\in H}R_c(h)\Pr[c]\\
&=\sum_{c\in H}\Pr_{x\in X}[h(x)\neq c(x)]\Pr[c]\\
&=\sum_{c\in H}\sum_{x\in X}1_{h(x)\neq c(x)}\Pr[x]\Pr[c]\\
&\geq\sum_{c\in H}\sum_{x\notin S}1_{h(x)\neq c(x)}\Pr[x]\Pr[c]\\
&=\sum_{x\notin S}\sum_{c\in H}1_{h(x)\neq c(x)}\Pr[c]\Pr[x]\\
&=\sum_{x\notin S}\Pr_{c\in H}[h(x)\neq c(x)]\Pr[x]\\
&=\sum_{x\notin S}\frac{1}{2}\Pr[x]\\
&=\frac{1}{2}\Pr_{x\in X}[x\notin S]=\frac{d-m'}{2d}
\end{split}
$$
