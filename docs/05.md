{% include lib/mathjax.html %}
#  การสร้าง robust classifier

เมื่อเรามีนิยามของ adversarial risk อย่างชัดเจนแล้ว ปัญหาในการเทรนแบบจำลองให้มีความทนทานสูงก็นิยามได้อย่างตรงไปตรงมา นั่นคือ สำหรับ training data $$D_\text{train}=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ เราต้องการหาพารามิเตอร์ $$\theta$$ ที่เป็นตำตอบของปัญหา optimization ต่อไปนี้

$$
\min_\theta\hat{R}(h_\theta,D_\text{train}) = \min_\theta\frac{1}{m}\sum_{i=1}^m\max_{\delta_i\in\Delta(x_i)}\ell(h_\theta(x_i+\delta_i),y_i)
$$

เราจะเรียก formulation นี้ว่าเป็น min-max หรือ robust optimization formulation สำหรับการทำ adversarial learning ซึ่งจะถูกกล่าวถึงบ่อย ๆ ต่อไป

วิธีหนึ่งในการแก้ปัญหานี้ ก็คือการใช้อัลกอริทึมการเทรนเช่นเดียวกับการเทรนแบบดั้งเดิม นั่นคือเราสามารถใช้ stochastic gradient descent สำหรับปรับค่า $$\theta$$ โดยในแต่ระรอบ เราทำการเลือก minibatch $$B\subseteq D_\text{train}$$ และทำการ update ค่าของ $$\theta$$ ในทิศทางตรงข้ามกับ gradient ดังนั้น

$$
\theta_{t+1}=\theta_t - \alpha\cdot\frac{1}{|B|}\sum_{(x,y)\in B}\nabla_\theta\max_{\delta\in\Delta(x)}\ell(h_theta(x+\delta),y)
$$

จะเห็นว่าข้อแตกต่างสำคัญระหว่างการทำ adversarial training กับการ traing แบบดั้งเดิมนั้นก็คือ ในกรณีของ adversarial training การคำนวณ gradient ตามต้องการนี้ไม่ใช่เรื่องง่าย เนื่องจากตัวฟังก์ชันที่สนใจนั้นมีปัญหา maximization อยู่ภายใน อย่างไรก็ดี [Danskin's theorem](https://en.wikipedia.org/wiki/Danskin's_theorem) ได้แสดงไว้ว่าเราสามารถหา gradient ของฟังก์ชัน max ได้จากการคำนวณ gradient ของฟังก์ชันที่อยู่ข้างใน max โดยใช้ค่าของตัวแปรที่ทำให้ฟังก์ชันภายในนี้มีค่ามากที่สุด นั่นคือ

$$
\frac{\partial}{\partial x}\max_{y\in Y}f(x,y) =\frac{\partial}{\partial x}f(x,y^*)
$$

เมื่อ 

$$
y^*=\argmax_{y\in Y}f(x,y)
$$
