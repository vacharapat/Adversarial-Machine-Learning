{% include lib/mathjax.html %}
#  การสร้าง robust classifier

เมื่อเรามีนิยามของ adversarial risk อย่างชัดเจนแล้ว ปัญหาในการเทรนแบบจำลองให้มีความทนทานสูงก็นิยามได้อย่างตรงไปตรงมา นั่นคือ สำหรับ training data $$D_\text{train}=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ เราต้องการหาพารามิเตอร์ $$\theta$$ ที่เป็นตำตอบของปัญหา optimization ต่อไปนี้

$$
\min_\theta\hat{R}(h_\theta,D_\text{train}) = \min_\theta\frac{1}{m}\sum_{i=1}^m\max_{\delta_i\in\Delta(x_i)}\ell(h_\theta(x_i+\delta_i),y_i)
$$

เราจะเรียก formulation นี้ว่าเป็น min-max หรือ robust optimization formulation สำหรับการทำ adversarial learning ซึ่งจะถูกกล่าวถึงบ่อย ๆ ต่อไป

วิธีหนึ่งในการแก้ปัญหานี้ ก็คือการใช้อัลกอริทึมการเทรนเช่นเดียวกับการเทรนแบบดั้งเดิม นั่นคือเราสามารถใช้ stochastic gradient descent สำหรับปรับค่า $$\theta$$ โดยในแต่ระรอบ เราทำการเลือก minibatch $$B\subseteq D_\text{train}$$ และทำการ update ค่าของ $$\theta$$ ในทิศทางตรงข้ามกับ gradient ดังนั้น

$$
\theta_{t+1}=\theta_t - \alphs\cdot\frac{1}{|B|}\sum_{(x,y)\in B}\nabla_\theta\max_{\delta\in\Delta(x)}\ell(h_theta(x+\delta),y)
$$
