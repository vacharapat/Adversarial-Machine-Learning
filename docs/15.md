{% include lib/mathjax.html %}
# การเรียนรู้แบบ Probably approximately correct

ในเนื้อหาส่วนนี้ เราจะศึกษาความรู้พื้นฐานด้าน _ทฤษฎีการเรียนรู้เชิงคำนวณ_ (computational learning theory) ซึ่งสนใจการวิเคราะห์แง่มุมต่าง ๆ ของปัญหาการเรียนรู้และอัลกอริทึมการเรียนรู้ เพื่อตอบคำถามต่าง ๆ เช่น ปัญหาใดสามารถเรียนรู้ได้อย่างมีประสิทธิภาพ หรือ ในปัญหาการเรียนรู้หนึ่ง เราต้องการตัวอย่างข้อมูลมากแค่ไหนจึงเพียงพอที่เรียนรู้ได้สำเร็จ หลังจากที่เราคุ้นเคยกับทฤษฎีพื้นฐานเหล่านี้ประมาณหนึ่ง เราจะกลับไปพิจารณาเกี่ยวกับการเรียนรู้แบบ adversarial กันต่อไป

## PAC framework

เพื่อศึกษาปัญหาการเรียนรู้ในภาพกว้าง ๆ เราจะทำการวิเคราะห์สิ่งที่สนใจภายใต้ learning framework ที่เรียกว่า _probably approximately correct_ หรือ PAC ซึ่งเป็น framework ที่มีความ general ค่อนข้างมาก

กำหนดให้ $$X$$ เป็น input space หรือเซตของข้อมูลทั้งหมด และ $$Y$$ เป็นเซตของ label เพื่อความง่ายเราจะพิจารณากรณีที่ label ที่เป็นไปได้มีจำนวนเพียง 2 เท่านั้น นั่นคือ $$Y=\{0,1\}$$ เราต้องการเรียนรู้ที่จะทำนาย label ใน $$Y$$ ที่ถูกต้องสำหรับ input $$x\in X$$ ใด ๆ ปัญหาการเรียนรู้เพื่อทำนาย label ที่ถูกต้องเช่นนี้มักเรียกว่าเป็นปัญหา classification 

เราจะเรียกฟังก์ชัน $$c:X\to Y$$ ใด ๆ ว่าเป็น _concept_ ซึ่งในกรณีที่ $$Y\{0,1\}$$  นั้น เราอาจมอง concept $$c$$ ในรูปของเซต $$\{x\in X: c(x)=1\}$$ ก็ได้

สมมติให้การสุ่มหยิบข้อมูลใน $$X$$ แต่ละครั้งนั้นมีความเป็นอิสระภายใต้การกระจายตัวแบบเดียวกัน (independently and identically distributed หรือ i.i.d.) โดยเราให้ $$D$$ แทนการกระจายตัวของข้อมูล เราสามารถนิยามปัญหาการเรียนรู้อย่างเป็นทางการได้ดังนี้

#### นิยาม ปัญหาการเรียนรู้ 
พิจารณาเซตของ concept จำนวนหนึ่งที่เราจะเรียกว่า hypothesis set $$H$$ หากเราได้รับเซตของตัวอย่างข้อมูลและ label ที่ถูกต้อง $$S=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ ซึ่งถูกสุ่มหยิบมาแบบ i.i.d. บนการกระจายตัว $$D$$ โดยที่ label ทั้งหมดสอดคล้องกับ concept $$c$$ concept หนึ่ง (นั่นคือ $$y_i=c(x_i)$$ สำหรับ $$i=1,\dots,m$$) เราต้องการหา hypothesis $$h\in H$$ ที่มี generalization error $$R(h)$$ เมื่อเทียบกับ $$c$$ น้อยที่สุด

โดยเรานิยาม generalization error $$R(h)$$ ดังนี้

#### นิยาม generalization error
สำหรับ hypothetsis $$h$$, concept เป้าหมาย $$c$$ และการกระจายตัวของข้อมูล $$D$$ generalization error ของ $$h$$ คือความน่าจะเป็นที่สุ่มหยิบข้อมูล $$x$$ จาก $$D$$ แล้วได้ว่า $$h$$ ทำนาย label ของ $$x$$ ไม่ตรงกับ $$c$$  หรือเราเขียนได้เป็น

$$
R(h)=\Pr_{x\sim D}[h(x)\neq c(x)]
$$

ถึงตรงนี้เราสามารถพูดถึงประสิทธิภาพในการเรียนรู้ของปัญหาการเรียนรู้ได้ดังนี้

#### นิยาม PAC learning
ให้ $$C$$ เป็นคลาสของ concept เราจะกล่าวว่าคลาส $$C$$ สามารถ _เรียนรู้ได้_ ถ้ามีอัลกอริทึม $$A$$ ที่ สำหรับค่าคงที่ $$\epsilon>0$$ และ $$\delta>0$$ ใด ๆ, concept $$c\in C$$ ใด ๆ, และการกระจายตัวของข้อมูล $$D$$ ใด ๆ $$A$$ สามารถให้ผลลัพธ์เป็น hypothesis $$h$$ ที่

$$
\Pr[R(h)\leq\epsilon]\geq 1-\delta
$$

ถ้า $$A$$ ใช้เวลาทำงานเป็น polynomial บน $$1/\epsilon, 1/\delta, n,$$ และ $$size(c)$$ เมื่อ $$n$$ เป็นขนาดของ representation ของ $$x\in X$$ ใด ๆ (เราอาจมองว่า $$n$$ เป็นมิติของ $$X$$ ก็ได้) และ $$size(c)$$ แทนขนาดของ representation ของ $$c$$ เราจะกล่าวว่าปัญหาดังกล่าวสามารถ _เรียนรู้ได้อย่างมีประสิทธิภาพ_ โดยทั่วไปแล้วอัลกอริทึมการเรียนรู้ที่เราสนใจมักมีการดำเนินการง่าย ๆ ต่อตัวอย่างข้อมูลแต่ละตัว ซึ่งทำให้เราสามารถวัดประสิทธิภาพของอัลกอริทึมจากจำนวนตัวอย่างข้อมูลที่ต้องการใช้แทนได้ เราเรียกจำนวนตัวอย่างข้อมูลที่ทำให้อัลกอริทึมเรียนรู้ได้สำเร็จว่า _sample complexity_ ของอัลกอริทึมนั้น
