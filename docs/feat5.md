{% include lib/mathjax.html %}
# ความสามารถของ weak feature

หลังจากที่เราได้เห็นความสามารถในการตัดสินใจของ robust feature กันมาแล้ว
คราวนี้เราจะมาลองดูความสามารถของ weak feature กันดูบ้าง โดยเราจะสร้างชุดข้อมูลใหม่ที่ทำให้
robust feature ทั้งหมดไม่สามารถใช้ช่วยในการตัดสินใจได้ นั่นคือเราจะทำให้ในชุดข้อมูลใหม่นั้นมีเพียง
weak feature ที่ยังคงเป็น useful feature อยู่ จากนั้นเราจะนำชุดข้อมูลที่ได้ไปเทรนแบบจำลองและนำมาทดสอบกับ
test data เดิมของเราดูเช่นเดียวกับการทดสอบความสามารถของ robust feature ก่อนหน้านี้

## การสร้าง weak-feature training set

ในการสร้างชุดข้อมูลให้มีเฉพาะ weak feature เท่านั้นที่เป็น useful feature เราเริ่มจากการสร้าง
standard classifier $C$ ซึ่งไม่มีความทนทานต่อการโจมตี จากนั้น สำหรับตัวอย่างข้อมูล $(x,y)$ แต่ละตัวใน
training set เราจะสร้างตัวอย่างข้อมูลใหม่ $(x',y')$ ด้วยวิธีการดังนี้

เราจะสุ่มคลาสเป้าหมาย $y'$ จากคลาสทั้งหมดให้มีความน่าจะเป็นที่จะได้แต่ละคลาสเท่ากัน
จากนั้นเราจะทำการโจมตีแบบกำหนดเป้าหมายเพื่อหา adversarial example $x'$ ที่ $C$ ทำนายว่าเป็นคลาส $y'$
โดยให้การก่อกวนมีขนาดเล็ก ๆ (ไม่เกิน $\epsilon$) การหา adversarial example $x'$ ดังกล่าวทำได้โดยการทำ
gradient descent เพื่อหา

$$
x' = {\arg\min}_{\|x'-x\|\leq\epsilon}\mathcal{L}_C(x', y')
$$

โดย $\mathcal{L}_C$ แทนฟังก์ชัน loss จาก classifier $C$ เมื่อเราหา $x'$ ดังกล่าวได้แล้ว
ก็จะได้ตัวอย่างข้อมูลใหม่เป็น $(x', y')$ ตามต้องการ

เราจะมาทำความเข้าใจกันก่อนว่าชุดของตัวอย่างข้อมูลที่สร้างขึ้นด้วยกระบวนการนี้จะทำให้มีเฉพาะ weak feature
ที่แบบจำลองสามารถนำไปใช้งานได้อย่างไร ก่อนอื่นสังเกตว่าเนื่องจาก adversarial example $x'$ นั้นมีความใกล้เคียงกับ $x$ อย่างมาก นั่นแสดงว่า robust feature ต่าง ๆ ของ $x'$ จะยังคง _ชี้_
ไปยังคลาส $y$ เช่นเดิม ดังนั้นการที่ $C$ ทำนายคลาสของ $x'$ ไปเป็น $y'$ ได้นั้น แสดงว่าจะต้องมี
weak feature ที่ชี้ไปหาคลาส $y'$ นั่นเอง

เนื่องจากสำหรับตัวอย่างข้อมูล $(x,y)$ แต่ละตัว เราเลือกคลาส $y'$ ใหม่โดยการสุ่ม
ดังนั้นจะเห็นว่าในบรรดาตัวอย่างข้อมูลเดิมที่เป็นคลาส $y$ เหมือนกัน อาจจะถูกโจมตีให้กลายเป็นคลาสเป็นคลาสที่แตกต่างกันอย่างไรก็ได้ ทั้ง ๆ ที่ตัวอย่างข้อมูลทั้งหมดนี้จะยังคงมี robust feature ที่ชี้ไปทิศทางเดียวกัน ตรงนี้ทำให้เห็นว่าในชุดข้อมูลใหม่ที่สร้างขึ้นมานั้น โดยเฉลี่ยแล้ว robust feature จะไม่มีทางเป็น useful feature ได้

ในทางกลับกัน ในชุดข้อมูลใหม่ เรากำหนด label $y'$ ให้ตรงกับที่ $C$ ทำนายจาก $x'$ เสมอ
แต่เนื่องจาก $x'$ แต่ละตัวนั้นไม่สอดคล้องกับ label $y'$ เลยในสายตามนุษย์ แสดงว่า feature ที่ทำให้
$C$ ตัดสินใจทำนายคลาสของ $x'$ เป็น $y'$ นั้นจะต้องเป็น weak feature นั่นคือ ใน
adversarial example $x'$ จะมี weak feature ของคลาส $y'$ อยู่ ดังนั้นเมื่อเรากำหนดให้ชุดข้อมูลใหม่ของเราประกอบด้วยตัวอย่างข้อมูล
$(x', y')$ ทั้งหมด ก็จะทำให้ weak feature เหล่านี้ยังคงใช้งานได้เช่นเดิม
โดยสรุป หากเราเรียกชุดข้อมูลใหม่นี้ว่า $\widehat{D}_{rand}$ เราจะได้ว่า

$$
\mathbb{E}_{(x, y)\in \widehat{D}_{rand}}[y\cdot f(x)]
\begin{cases}
> 0 & \text{ ถ้า } f \text{ เป็น weak feature บน } D\\
\approx 0 & \text{ กรณีอื่น}
\end{cases}
$$


## References

1. [I. Goodfellow, J. Shlens, C. Szegedy. Explaining and Harnessing Adversarial Examples,
In Intenational Conference on Learning Representations (ICLR), 2015](https://arxiv.org/abs/1412.6572)

---
Prev: [การเทรนแบบจำลองด้วย robust features](https://vacharapat.github.io/Adversarial-Machine-Learning/docs/feat4)

Next:
