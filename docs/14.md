{% include lib/mathjax.html %}
# Semidefinite programming relaxation

เมื่อเราเขียนปัญหาการโจมตีแบบกำหนดเป้าหมายให้อยู่ในรูปของ quadratic programming ได้แล้ว เราจะสามารถทำ relaxation ให้กลายเป็นปัญหาที่เรียกว่า semidefinite programming ซึ่งสามารถหาคำตอบได้ไม่ยาก อย่างไรก็ดีในปัญหา semidefinite programming นั้นเราจะมองตัวแปรที่ปรับค่าได้ในรูปของ matrix เราจึงควรจัดรูปปัญหาของเราให้เป็นปัญหาบน matrix ก่อน ซึ่งทำได้ง่ายเมื่อปัญหาที่เรามีอยู่ในรูป quadratic programming อยู่แล้ว

## relaxation สำหรับแบบจำลอง deep learning ที่มี 1 hidden layer
เพื่อความง่ายเราจะเริ่มพิจารณากรณีที่แบบจำลองของเรามี hidden layer เพียง layer เดียวก่อน ซึ่งจะสามารถเขียนในรูปปัญหา quadratic programming ได้ดังนี้

$$
\begin{array}{ll}
\max_{z_1,z_2} &(e_{y'}-e_y)W_2z_2\\
\text{subject to}\\
& z_1^2-(l+u)z_1+lu\leq 0\\
& z_2\geq W_1z_1+b_1\\
& z_2\geq 0\\
& z_2^2 -W_1z_1z_2 -b_1z_2 = 0
\end{array}
$$

ถ้าเรานิยามให้ $$v=\begin{bmatrix}1\\z_1\\z_2\end{bmatrix}$$ และให้ $$P=vv^T$$ เราจะใช้สัญลักษณ์ $$P[\cdot]$$ ในการระบุถึงสมาชิกของ $$P$$ ดังนี้

$$
P=\begin{bmatrix}
P[1] &P[z_1^T] & P[z_2^T]\\
P[z_1] & P[z_1z_1^T] & P[z_1z_2^T]\\
P[z_2] & P[z_2z_1^T] & P[z_2z_2^T]
\end{bmatrix}
$$

ถึงตรงนี้เราสามารถเขียนปัญหาของเราใหม่ในรูปของ $$P$$ ได้ดังนี้

$$
\begin{array}{ll}
\max_P & (e_{y'}-e_y)W_2P[z_2]\\
\text{subject to}&\\
& \text{diag}(P[z_1z_1^T])-(l+u)\cdot P[z_1]+l\cdot u\leq 0\\
& P[z_2]\geq W_1\cdot P[z_1]+b_1\\
& P[z_2]\geq 0\\
& \text{diag}(P[z_2z_2^T])-W_1\cdot \text{diag}(P[z_1z_2^T])-b_1\cdot P[z_2] = 0\\
& P[1] = 1\\
& P = vv^T, \text{ for some vector } $$v$$
\end{array}
$$
